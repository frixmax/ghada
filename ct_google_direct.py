#!/usr/bin/env python3
"""
Monitoring Certificate Transparency - TOUS les logs Google
Version compl√®te avec tous les endpoints
"""

import requests
import json
import time
import os
import threading
from datetime import datetime
from http.server import HTTPServer, BaseHTTPRequestHandler

print("=== MONITORING CT - TOUS LES LOGS GOOGLE ===")
print(f"Date: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}")

# Configuration
PORT = int(os.environ.get('PORT', 10000))
DISCORD_WEBHOOK = os.environ.get('DISCORD_WEBHOOK', "VOTRE_WEBHOOK_ICI")
DOMAINS_FILE = '/app/domains.txt'
CHECK_INTERVAL = int(os.environ.get('CHECK_INTERVAL', 60))  # Configurable
BATCH_SIZE = 256

# TOUS les logs Google Certificate Transparency (2026)
CT_LOGS = [
    # US Logs
    {"name": "Argon 2026h1", "url": "https://ct.googleapis.com/logs/us1/argon2026h1", "enabled": True},
    {"name": "Argon 2026h2", "url": "https://ct.googleapis.com/logs/us1/argon2026h2", "enabled": True},
    
    # EU Logs  
    {"name": "Solera 2026h1", "url": "https://ct.googleapis.com/logs/eu1/solera2026h1", "enabled": True},
    {"name": "Solera 2026h2", "url": "https://ct.googleapis.com/logs/eu1/solera2026h2", "enabled": True},
    
    # 2025 Logs (encore actifs)
    {"name": "Argon 2025h1", "url": "https://ct.googleapis.com/logs/us1/argon2025h1", "enabled": False},
    {"name": "Argon 2025h2", "url": "https://ct.googleapis.com/logs/us1/argon2025h2", "enabled": False},
    {"name": "Solera 2025h1", "url": "https://ct.googleapis.com/logs/eu1/solera2025h1", "enabled": False},
    {"name": "Solera 2025h2", "url": "https://ct.googleapis.com/logs/eu1/solera2025h2", "enabled": False},
    
    # Trust Asia Logs
    {"name": "TrustAsia CT2025", "url": "https://ct.trustasia.com/log2025", "enabled": False},
    
    # Cloudflare Logs
    {"name": "Cloudflare Nimbus 2026", "url": "https://ct.cloudflare.com/logs/nimbus2026", "enabled": False},
]

# Stats
stats = {
    'certificats_analys√©s': 0,
    'alertes_envoy√©es': 0,
    'derni√®re_alerte': None,
    'd√©marrage': datetime.utcnow(),
    'derni√®re_v√©rification': None,
    'positions': {},
    'logs_actifs': 0,
    'logs_en_erreur': {},
    'duplicates_√©vit√©s': 0
}

# Cache pour √©viter les duplicates
seen_certificates = set()
CACHE_MAX_SIZE = 10000

# Chargement des domaines
try:
    with open(DOMAINS_FILE, 'r') as f:
        targets = {line.strip().lower() for line in f if line.strip() and not line.startswith('#')}
    print(f"‚úì {len(targets)} domaines charg√©s")
    if targets:
        print(f"  Exemples: {', '.join(list(targets)[:3])}")
except Exception as e:
    print(f"‚úó Erreur chargement domaines: {e}")
    targets = set()

if not targets:
    print("‚úó ERREUR: Aucun domaine √† surveiller")
    exit(1)

# Validation webhook
if "discord.com/api/webhooks" not in DISCORD_WEBHOOK:
    print("‚úó ERREUR: Webhook Discord invalide")
    exit(1)
print(f"‚úì Webhook Discord configur√©")

# Compter les logs actifs
stats['logs_actifs'] = sum(1 for log in CT_LOGS if log['enabled'])
print(f"‚úì {stats['logs_actifs']} logs CT actifs sur {len(CT_LOGS)} disponibles")

class HealthCheckHandler(BaseHTTPRequestHandler):
    """Handler HTTP pour health checks"""
    
    def log_message(self, format, *args):
        pass
    
    def do_GET(self):
        if self.path == '/health' or self.path == '/':
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            
            uptime = (datetime.utcnow() - stats['d√©marrage']).total_seconds()
            
            status = {
                'status': 'healthy',
                'uptime_seconds': int(uptime),
                'certificats_analys√©s': stats['certificats_analys√©s'],
                'alertes_envoy√©es': stats['alertes_envoy√©es'],
                'duplicates_√©vit√©s': stats['duplicates_√©vit√©s'],
                'logs_actifs': stats['logs_actifs'],
                'logs_en_erreur': stats['logs_en_erreur'],
                'derni√®re_alerte': stats['derni√®re_alerte'].isoformat() if stats['derni√®re_alerte'] else None,
                'derni√®re_v√©rification': stats['derni√®re_v√©rification'].isoformat() if stats['derni√®re_v√©rification'] else None,
                'timestamp': datetime.utcnow().isoformat(),
                'logs_positions': stats['positions']
            }
            
            self.wfile.write(json.dumps(status, indent=2).encode())
        else:
            self.send_response(404)
            self.end_headers()

def start_http_server():
    """D√©marre le serveur HTTP"""
    server = HTTPServer(('0.0.0.0', PORT), HealthCheckHandler)
    print(f"‚úì Serveur HTTP d√©marr√© sur le port {PORT}")
    server.serve_forever()

def get_sth(log_url, log_name):
    """R√©cup√®re le Signed Tree Head"""
    try:
        response = requests.get(f"{log_url}/ct/v1/get-sth", timeout=10)
        response.raise_for_status()
        
        # R√©initialiser le compteur d'erreurs
        if log_name in stats['logs_en_erreur']:
            del stats['logs_en_erreur'][log_name]
        
        return response.json()['tree_size']
    except Exception as e:
        stats['logs_en_erreur'][log_name] = str(e)
        return None

def get_entries(log_url, start, end):
    """R√©cup√®re les entr√©es CT"""
    try:
        response = requests.get(
            f"{log_url}/ct/v1/get-entries",
            params={"start": start, "end": end},
            timeout=30
        )
        response.raise_for_status()
        return response.json().get('entries', [])
    except Exception as e:
        return []

def generate_cert_hash(entry):
    """G√©n√®re un hash pour d√©tecter les duplicates"""
    try:
        leaf = entry.get('leaf_input', '')
        return hash(leaf)
    except:
        return None

def parse_certificate(entry):
    """Parse un certificat pour extraire les domaines"""
    try:
        from base64 import b64decode
        
        leaf_input = entry.get('leaf_input', '')
        extra_data = entry.get('extra_data', '')
        
        domains = []
        data_str = str(leaf_input) + str(extra_data)
        
        for target in targets:
            if target in data_str.lower():
                domains.append(target)
        
        return list(set(domains))
        
    except Exception as e:
        return []

def send_alert(matched_domains, log_name):
    """Envoie une alerte Discord"""
    try:
        description = "\n".join([f"‚Ä¢ `{d}`" for d in sorted(set(matched_domains))[:20]])
        
        if len(matched_domains) > 20:
            description += f"\n\n... et {len(matched_domains) - 20} autre(s)"
        
        embed = {
            "title": f"üö® Nouveau certificat SSL d√©tect√©",
            "description": description,
            "color": 0xff0000,
            "fields": [
                {
                    "name": "Nombre de domaines",
                    "value": str(len(matched_domains)),
                    "inline": True
                },
                {
                    "name": "Source",
                    "value": log_name,
                    "inline": True
                }
            ],
            "footer": {"text": "CT Monitor - Multi-logs"},
            "timestamp": datetime.utcnow().isoformat()
        }
        
        payload = {"embeds": [embed]}
        response = requests.post(DISCORD_WEBHOOK, json=payload, timeout=10)
        response.raise_for_status()
        
        stats['alertes_envoy√©es'] += 1
        stats['derni√®re_alerte'] = datetime.utcnow()
        print(f"‚úì Alerte envoy√©e: {len(matched_domains)} domaine(s) depuis {log_name}")
        
    except Exception as e:
        print(f"‚úó Erreur Discord: {e}")

def monitor_log(log_config):
    """Surveille un log CT"""
    log_name = log_config['name']
    log_url = log_config['url']
    
    # Initialiser la position
    if log_name not in stats['positions']:
        tree_size = get_sth(log_url, log_name)
        if tree_size:
            stats['positions'][log_name] = max(0, tree_size - 500)
            print(f"‚úì Init {log_name}: position {stats['positions'][log_name]}")
        else:
            return
    
    # R√©cup√©rer la taille actuelle
    tree_size = get_sth(log_url, log_name)
    if not tree_size:
        return
    
    current_pos = stats['positions'][log_name]
    
    if current_pos >= tree_size:
        return
    
    end_pos = min(current_pos + BATCH_SIZE, tree_size)
    
    print(f"üîç {log_name}: {current_pos} ‚Üí {end_pos - 1}")
    
    entries = get_entries(log_url, current_pos, end_pos - 1)
    
    for entry in entries:
        stats['certificats_analys√©s'] += 1
        
        # V√©rifier les duplicates
        cert_hash = generate_cert_hash(entry)
        if cert_hash and cert_hash in seen_certificates:
            stats['duplicates_√©vit√©s'] += 1
            continue
        
        # Ajouter au cache
        if cert_hash:
            seen_certificates.add(cert_hash)
            # Limiter la taille du cache
            if len(seen_certificates) > CACHE_MAX_SIZE:
                seen_certificates.pop()
        
        # Parser et chercher matches
        matched = parse_certificate(entry)
        
        if matched:
            send_alert(matched, log_name)
    
    stats['positions'][log_name] = end_pos
    
    if stats['certificats_analys√©s'] % 500 == 0:
        print(f"üìä {stats['certificats_analys√©s']} certificats analys√©s")

# D√©marrer le serveur HTTP
http_thread = threading.Thread(target=start_http_server, daemon=True)
http_thread.start()
time.sleep(1)

print(f"\nüîÑ Surveillance toutes les {CHECK_INTERVAL}s...")

# Boucle principale
while True:
    try:
        stats['derni√®re_v√©rification'] = datetime.utcnow()
        
        for log_config in CT_LOGS:
            if log_config['enabled']:
                monitor_log(log_config)
        
        time.sleep(CHECK_INTERVAL)
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Arr√™t demand√©")
        break
    except Exception as e:
        print(f"‚úó Erreur globale: {e}")
        time.sleep(30)

print("=== ARR√äT DU MONITORING ===")
